import openai
import config
import typer
from rich import print
from rich.table import Table
"""
Al comienzo del programa, importa los mÃ³dulos necesarios, incluidos openai,
config.py (archivo con la clave API), typer, Table y print desde rich.
"""

"""
main(): Esta es la funciÃ³n principal que ejecuta todo el programa.
Configura la clave API y crea un contexto inicial para el asistente de IA.
Luego crea un ciclo donde puede ingresar entradas de chat y recibir respuestas del asistente.
"""
def main():
    openai.api_key = config.api_key

    print("\nğŸ—¨ï¸ [bold blue]ChatGPT API con Python.[/bold blue]\n")
    table = Table("Comando", "DescripciÃ³n")
    table.add_row("exit", "Salir de la aplicaciÃ³n")
    table.add_row("new", "Crear una nueva conversaciÃ³n")
    table.add_row("context", "Cambiar el contexto del asistente")
    print(table)
    """
    Luego, el programa presenta una tabla de comandos disponibles al usuario mediante la funciÃ³n
    Table().
    """

    # Contexto inicial del asistente
    initial_context = {"role": "system", "content": "Eres un asistente muy Ãºtil"}
    context = initial_context
    messages = [context]
    """
    Luego, el programa define el contexto inicial para el asistente de IA, que es un diccionario
    con dos partes, "rol" y "contenido", que representan el propÃ³sito del contexto y
    el contenido del texto del contexto, respectivamente.
    """

    while True:
        content = __prompt()

        if content == "new":
            print("\nğŸ—¨ï¸ Â¡Nueva conversaciÃ³n creada!")
            context = initial_context
            messages = [context]
            content = __prompt()

        # Cambiar el contexto del asistente
        if content == "context":            
            context_content = typer.prompt("\nÂ¿CuÃ¡l es el nuevo contexto?")
            context = {"role": "system", "content": context_content}
            messages = [context]
            content = __prompt()
            
        messages.append({"role": "user", "content": content})

        response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=messages)

        response_content = response.choices[0].message.content

        messages.append({"role": "assistant", "content": response_content})
        """
        Luego, el programa ingresa a un ciclo donde recopila la entrada del usuario, agrega
        la entrada del usuario a una lista de mensajes, solicita a la IA que genere una respuesta
        basada en la lista de mensajes proporcionados y agrega la respuesta resultante a la
        lista de mensajes.
        """

        # Respuesta generada por el asistente
        print(f"\n[bold green]> [/bold green] [green]{response_content}[/green]")

"""
__prompt(): esta es una funciÃ³n de ayuda que recupera la entrada del usuario (un prompt)
durante la conversaciÃ³n. TambiÃ©n maneja el caso en el que el usuario quiere salir del programa.
"""
def __prompt() -> str:
    prompt = typer.prompt("\nprompt")

    if prompt == "exit":
        exit = typer.confirm("\nÂ¿EstÃ¡s seguro?ğŸ–ï¸")
        if exit:
            print("\nÂ¡Hasta luego!ğŸ‘‹\n")
            raise typer.Exit
        return __prompt()
    
    return prompt

"""
La lÃ­nea if __name__ == "__main__": se utiliza para comprobar si el script se estÃ¡ ejecutando
como un programa principal, es decir, si se ha ejecutado desde la lÃ­nea de comandos o consola,
y que no se ha importado como un mÃ³dulo a otro script. 

Si la lÃ­nea anterior es verdadera, entonces typer.run(main) es llamado. Esto ejecutarÃ¡ la
funciÃ³n main que contiene el cÃ³digo principal del programa.  
"""
if __name__ == "__main__":
    typer.run(main)